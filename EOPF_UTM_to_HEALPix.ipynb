{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Skelton Notebook Converting EOPF Zarr format in UTM to HEALPix \n",
    "We use EOPF Sample service data here. \n",
    "This workflow can be applied to any UTM expressed EOPF ZARR format. \n",
    "\n",
    "## Install dependencies — HEALPix indexing/operations\n",
    "\n",
    "- Installs required Python packages for this notebook. Uses HEALPix to index or transform gridded Earth data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xarray-eopf foscat xdggs healpix-geo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "<!-- auto-md: healpix_zarr_dask -->\n",
    "### Imports and setup\n",
    "\n",
    "- Loads libraries: matplotlib, numpy, xarray. Configures plotting options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyproj\n",
    "import pystac_client\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Open datasets with Xarray \n",
    "\n",
    "\n",
    "- Opens datasets using Xarray (lazy loading with Dask if chunked).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access cloud-optimized Sentinel-2 data via the EOPF STAC catalog\n",
    "catalog = pystac_client.Client.open(\"https://stac.core.eopf.eodc.eu\")\n",
    "\n",
    "# Define oceanographic study area and time window\n",
    "LON, LAT = -4.5, 48  # Bay of Biscay - known for consistent wave patterns\n",
    "date = \"2025-06-17/2025-06-17\"\n",
    "\n",
    "# Search criteria optimized for wave analysis\n",
    "collections = [\"sentinel-2-l1c\"]\n",
    "items = list(\n",
    "    catalog.search(\n",
    "        datetime=date,\n",
    "        collections=collections,\n",
    "        intersects=dict(type=\"Point\", coordinates=[LON, LAT]),\n",
    "        query={\n",
    "            \"eo:cloud_cover\": {\n",
    "                \"lt\": 20\n",
    "            },  # Cloud cover < 20% ensures clear ocean surface\n",
    "            \"view:sun_elevation\": {\n",
    "                \"gt\": 25\n",
    "            },  # Filter for high sun elevation > 25° (→ sun zenith angle < 65°),\n",
    "            # which places the sun near the zenith.\n",
    "        },\n",
    "    ).items()\n",
    ")\n",
    "\n",
    "for item in items:\n",
    "    print(f\"✅ {item.id}\")\n",
    "\n",
    "item = items[0]\n",
    "\n",
    "# Open the dataset lazily from object storage\n",
    "dt = xr.open_datatree(\n",
    "    item.assets[\"product\"].href,\n",
    "    **item.assets[\"product\"].extra_fields[\"xarray:open_datatree_kwargs\"],\n",
    ")\n",
    "\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chose small area in UTM\n",
    "## TODO, we can update here to chose  'one detection' area.\n",
    "\n",
    "small_dt = dt.sel(\n",
    "    x=slice(\n",
    "        dt[\"conditions\"][\"geometry\"][\"sun_angles\"].x[0],\n",
    "        dt[\"conditions\"][\"geometry\"][\"sun_angles\"].x[2],\n",
    "    ),\n",
    "    y=slice(\n",
    "        dt[\"conditions\"][\"geometry\"][\"sun_angles\"].y[-3],\n",
    "        dt[\"conditions\"][\"geometry\"][\"sun_angles\"].y[-1],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see , probably a boat.\n",
    "# Todo, add plot for small_dt['conditions']['l1c_quicklook']['r10m']\n",
    "# small_dt['conditions']['l1c_quicklook']['r10m'].hvplot.rgb(x='x',y='y', )\n",
    "\n",
    "small_dt[\"measurements\"][\"reflectance\"][\"r10m\"][\"b02\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Annotate UTM with latitude and Longitude \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_latlon(ds: xr.Dataset, transformer: pyproj.Transformer) -> xr.Dataset:\n",
    "    \"\"\"Attach latitude/longitude coords + CF metadata to a Dataset with (x,y).\"\"\"\n",
    "    if not {\"x\", \"y\"}.issubset(ds.dims):\n",
    "        return ds\n",
    "\n",
    "    xx, yy = np.meshgrid(ds[\"x\"].values, ds[\"y\"].values, indexing=\"xy\")\n",
    "    lon, lat = transformer.transform(xx, yy)\n",
    "\n",
    "    ds = ds.assign_coords(\n",
    "        longitude=((\"y\", \"x\"), lon),\n",
    "        latitude=((\"y\", \"x\"), lat),\n",
    "    )\n",
    "    ds[\"latitude\"].attrs.update(\n",
    "        {\n",
    "            \"standard_name\": \"latitude\",\n",
    "            \"long_name\": \"Latitude\",\n",
    "            \"units\": \"degrees_north\",\n",
    "            \"axis\": \"Y\",\n",
    "        }\n",
    "    )\n",
    "    ds[\"longitude\"].attrs.update(\n",
    "        {\n",
    "            \"standard_name\": \"longitude\",\n",
    "            \"long_name\": \"Longitude\",\n",
    "            \"units\": \"degrees_east\",\n",
    "            \"axis\": \"X\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Make sure vars with (y,x) advertise the aux coords\n",
    "    for var in ds.data_vars:\n",
    "        if {\"y\", \"x\"}.issubset(ds[var].dims):\n",
    "            existing = ds[var].attrs.get(\"coordinates\", \"\").split()\n",
    "            ds[var].attrs[\"coordinates\"] = \" \".join(\n",
    "                sorted(set(existing) | {\"latitude\", \"longitude\"})\n",
    "            )\n",
    "    return ds\n",
    "\n",
    "\n",
    "def add_latlon(\n",
    "    path: str, ds: xr.Dataset, transformer: pyproj.Transformer\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"Wrapper for safe application on a node dataset.\"\"\"\n",
    "    if ds is None:\n",
    "        print(path, \"no dataset\")\n",
    "        return ds\n",
    "    if not {\"x\", \"y\"}.issubset(ds.dims):\n",
    "        print(path, \"not both x,y\")\n",
    "        return ds\n",
    "    return _add_latlon(ds, transformer)\n",
    "\n",
    "\n",
    "def add_latlon_to_dt(dt: xr.DataTree) -> xr.DataTree:\n",
    "    \"\"\"Return a new DataTree with latitude/longitude coords added everywhere possible.\"\"\"\n",
    "    crs_code = dt.attrs[\"other_metadata\"][\"horizontal_CRS_code\"]\n",
    "    src_crs = pyproj.CRS.from_string(crs_code)\n",
    "    transformer = pyproj.Transformer.from_crs(\n",
    "        src_crs, pyproj.CRS.from_epsg(4326), always_xy=True\n",
    "    )\n",
    "    return xr.DataTree.from_dict(\n",
    "        {\n",
    "            path: add_latlon(path, node.ds, transformer)\n",
    "            for path, node in dt.subtree_with_keys\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "latlon_dt = add_latlon_to_dt(small_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "latlon_dt[\"measurements\"][\"reflectance\"][\"r10m\"][\"b02\"].plot(\n",
    "    x=\"longitude\", y=\"latitude\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update to Authalic\n",
    "# todo, ask JM/Justus to check\n",
    "# todo, if this function already exist in healpix_geo, call that function\n",
    "\n",
    "\n",
    "# ---- WGS84 constants ----\n",
    "a = 6378137.0\n",
    "f = 1 / 298.257223563\n",
    "e2 = 2 * f - f * f\n",
    "e = np.sqrt(e2)\n",
    "\n",
    "\n",
    "# ---- one packed NumPy function (array-in, array-out) ----\n",
    "def _authalic_beta_numpy(lat_deg: np.ndarray) -> np.ndarray:\n",
    "    lat = np.deg2rad(lat_deg)\n",
    "\n",
    "    # avoid log(0) at exact poles\n",
    "    s = np.sin(lat)\n",
    "    s = np.clip(s, -1.0 + 1e-15, 1.0 - 1e-15)\n",
    "\n",
    "    one_minus_e2 = 1.0 - e2\n",
    "    q = one_minus_e2 * (\n",
    "        (s / (1.0 - e2 * s * s))\n",
    "        - (1.0 / (2.0 * e)) * np.log((1.0 - e * s) / (1.0 + e * s))\n",
    "    )\n",
    "    qp = 1.0 - one_minus_e2 / (2.0 * e) * np.log((1.0 - e) / (1.0 + e))\n",
    "\n",
    "    ratio = np.clip(q / qp, -1.0, 1.0)\n",
    "    beta = np.arcsin(ratio)\n",
    "\n",
    "    # keep exact poles unchanged (β = φ)\n",
    "    beta = np.where(np.isclose(np.abs(lat), np.pi / 2), lat, beta)\n",
    "\n",
    "    return np.rad2deg(beta)\n",
    "\n",
    "\n",
    "# Optional thin wrapper (keeps your original name)\n",
    "def update_latitude_to_authalic(lat_da: xr.DataArray) -> xr.DataArray:\n",
    "    # Single apply_ufunc call; no vectorization loops, no dask parallelization.\n",
    "    beta = xr.apply_ufunc(\n",
    "        _authalic_beta_numpy,\n",
    "        lat_da,\n",
    "        vectorize=False,  # pass whole ndarray to our packed NumPy function\n",
    "        dask=None,  # avoid dask-specific behavior\n",
    "        keep_attrs=True,\n",
    "    )\n",
    "    return beta\n",
    "\n",
    "\n",
    "# If you prefer to avoid apply_ufunc entirely (loads coord into memory):\n",
    "# def update_latitude_to_authalic(lat_da: xr.DataArray) -> xr.DataArray:\n",
    "#     data = _authalic_beta_numpy(np.asarray(lat_da))\n",
    "#     return xr.DataArray(data, coords=lat_da.coords, dims=lat_da.dims, attrs=lat_da.attrs)\n",
    "\n",
    "\n",
    "def _swich_to_authalic(ds: xr.Dataset) -> xr.Dataset:\n",
    "    if ds is None:\n",
    "        return ds\n",
    "    if not ((\"latitude\" in ds.coords) and (\"longitude\" in ds.coords)):\n",
    "        return ds\n",
    "\n",
    "    lat_auth = update_latitude_to_authalic(ds[\"latitude\"])\n",
    "    ds = ds.assign_coords(latitude=lat_auth)\n",
    "\n",
    "    ds[\"latitude\"].attrs.update(\n",
    "        {\n",
    "            \"standard_name\": \"authalic_latitude\",  # note: not a CF standard_name\n",
    "            \"long_name\": \"Authalic Latitude\",\n",
    "            \"units\": \"degrees_north\",\n",
    "            \"axis\": \"Y\",\n",
    "            \"comment\": \"Converted from WGS84 geodetic latitude to authalic latitude (equal-area sphere).\",\n",
    "        }\n",
    "    )\n",
    "    ds[\"longitude\"].attrs.setdefault(\"units\", \"degrees_east\")\n",
    "    ds[\"longitude\"].attrs.setdefault(\"axis\", \"X\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "def _switch_to_authalic(ds: xr.Dataset) -> xr.Dataset:\n",
    "    return _swich_to_authalic(ds)\n",
    "\n",
    "\n",
    "def swich_to_authalic(path: str, ds: xr.Dataset) -> xr.Dataset:\n",
    "    if ds is None:\n",
    "        print(path, \"no dataset\")\n",
    "        return ds\n",
    "    if not ((\"latitude\" in ds.coords) and (\"longitude\" in ds.coords)):\n",
    "        print(path, \"not both lat,lon\")\n",
    "        return ds\n",
    "    return _swich_to_authalic(ds)\n",
    "\n",
    "\n",
    "def add_latlon_to_dt(dt: \"xr.DataTree\") -> \"xr.DataTree\":\n",
    "    mapping = {\n",
    "        path: swich_to_authalic(path, node.ds) for path, node in dt.subtree_with_keys\n",
    "    }\n",
    "    return xr.DataTree.from_dict(mapping)\n",
    "\n",
    "\n",
    "def authalic(dt: \"xr.DataTree\") -> \"xr.DataTree\":\n",
    "    return add_latlon_to_dt(dt)\n",
    "\n",
    "\n",
    "authalic_dt = authalic(latlon_dt)\n",
    "authalic_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "authalic_dt[\"measurements\"][\"reflectance\"][\"r10m\"][\"b02\"].plot(\n",
    "    x=\"longitude\", y=\"latitude\"\n",
    ")\n",
    "\n",
    "# todo : plot quicklook\n",
    "# authalic_dt['conditions']['l1c_quicklook']['r10m'].hvplot.rgb(x='x',y='y', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to HEALPix.\n",
    "# Todo here: add 'data_tree' branch that indicate 'Healpix_level', i.e. instead of r10m,\n",
    "# we use 19, or level_19 or something which does pyramidal.\n",
    "# but this nomination r10m, it is comming from where? L1B??\n",
    "\n",
    "\n",
    "from healpix_geo.nested import lonlat_to_healpix\n",
    "\n",
    "# --- level selection (coarsest grid not finer than dx) ---\n",
    "EARTH_RADIUS_M = 6_371_000.0  # radius used in healpix-geo levels table\n",
    "\n",
    "\n",
    "def _healpix_edge_length_m(level: int, radius_m: float = EARTH_RADIUS_M) -> float:\n",
    "    # edge = R * sqrt(pi/3) / 2**level  (matches healpix-geo \"levels\" page)\n",
    "    return radius_m * np.sqrt(np.pi / 3.0) / (2**level)\n",
    "\n",
    "\n",
    "def _infer_dx_from_x(ds: xr.Dataset) -> float:\n",
    "    x = np.asarray(ds[\"x\"].values)\n",
    "    dx = float(np.nanmedian(np.abs(np.diff(x))))\n",
    "    if not np.isfinite(dx) or dx <= 0:\n",
    "        raise ValueError(\"Could not infer a positive spacing from ds['x'].\")\n",
    "    return dx\n",
    "\n",
    "\n",
    "def choose_healpix_level_from_dx(\n",
    "    ds: xr.Dataset, min_level: int = 0, max_level: int = 29\n",
    ") -> int:\n",
    "    dx = _infer_dx_from_x(ds)\n",
    "    base = EARTH_RADIUS_M * np.sqrt(np.pi / 3.0)\n",
    "    level = int(np.floor(np.log2(base / dx)))  # edge(level) >= dx\n",
    "    return int(np.clip(level, min_level, max_level))\n",
    "\n",
    "\n",
    "# --- single-dataset transform -> grouped by unique HEALPix cell_ids ---\n",
    "def to_healpix_cells_grouped_mean(\n",
    "    ds: xr.Dataset, level: int | None = None, ellipsoid: str = \"WGS84\"\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Returns a dataset with dims (angle, cell_ids), where 'cell_ids' is a\n",
    "    dimension/coordinate containing unique HEALPix ids (NESTED).\n",
    "    Values are averaged over all source samples that mapped to the same cell.\n",
    "    \"\"\"\n",
    "    if not {\"y\", \"x\"}.issubset(ds.dims):\n",
    "        raise ValueError(\"Dataset must have 'y' and 'x' dimensions.\")\n",
    "    if not {\"latitude\", \"longitude\"}.issubset(ds.coords):\n",
    "        raise ValueError(\n",
    "            \"Dataset must have 'latitude' and 'longitude' coords (degrees).\"\n",
    "        )\n",
    "\n",
    "    if level is None:\n",
    "        level = choose_healpix_level_from_dx(ds)\n",
    "\n",
    "    # 1) hash each (lon,lat) to HEALPix nested cell id\n",
    "    lon = ds[\"longitude\"].values.ravel()\n",
    "    lat = ds[\"latitude\"].values.ravel()\n",
    "    cell_ids = lonlat_to_healpix(lon, lat, level, ellipsoid=ellipsoid)\n",
    "\n",
    "    # 2) stack (y,x) -> cells\n",
    "    out = ds.stack(cells=(\"y\", \"x\"))\n",
    "\n",
    "    # 3) attach cell_ids coord on 'cells'\n",
    "    out = out.assign_coords(cell_ids=(\"cells\", cell_ids.astype(\"int64\")))\n",
    "    out[\"cell_ids\"].attrs.update(\n",
    "        {\n",
    "            \"grid_name\": \"healpix\",\n",
    "            \"level\": level,\n",
    "            \"indexing_scheme\": \"nested\",\n",
    "        }\n",
    "    )\n",
    "    cell_ids_attrs = dict(out[\"cell_ids\"].attrs)  # keep for after groupby\n",
    "\n",
    "    # 4) drop redundant coords/vars\n",
    "    #    drop_these = [n for n in (\"x\", \"y\", \"latitude\", \"longitude\") if n in out.variables]\n",
    "    #    out = out.drop_vars(drop_these)\n",
    "\n",
    "    # 5) group by cell_ids and average -> new dim named 'cell_ids'\n",
    "    out = out.groupby(\"cell_ids\").mean()\n",
    "\n",
    "    # 6) restore attrs on the new dimension coordinate\n",
    "    if \"cell_ids\" in out.coords:\n",
    "        out[\"cell_ids\"].attrs.update(cell_ids_attrs)\n",
    "\n",
    "    # 7) keep order stable for variables like (angle, cell_ids)\n",
    "    #   for v in out.data_vars:\n",
    "    #       if (\"angle\" in out[v].dims) and (\"cell_ids\" in out[v].dims):\n",
    "    #           out[v] = out[v].transpose(\"angle\", \"cell_ids\", ...)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# --- per-node handler for the DataTree pass ---\n",
    "def _add_healpix_to_dt_node(path: str, ds: xr.Dataset) -> xr.Dataset:\n",
    "    if ds is None:\n",
    "        print(path, \"no dataset — keeping empty node\")\n",
    "        return xr.Dataset()\n",
    "\n",
    "    has_xy = {\"x\", \"y\"}.issubset(ds.dims)\n",
    "    has_ll = {\"latitude\", \"longitude\"}.issubset(ds.coords)\n",
    "\n",
    "    if has_xy and not has_ll:\n",
    "        # stop the whole operation as requested\n",
    "        raise RuntimeError(\n",
    "            f\"{path}: has x/y but missing latitude/longitude — aborting.\"\n",
    "        )\n",
    "\n",
    "    if has_ll and has_xy:\n",
    "        depth = choose_healpix_level_from_dx(ds)\n",
    "        print(\n",
    "            f\"{path}: chosen level {depth} (edge≈{_healpix_edge_length_m(depth):.4f} m)\"\n",
    "        )\n",
    "        return to_healpix_cells_grouped_mean(ds, level=depth, ellipsoid=\"WGS84\")\n",
    "\n",
    "    # no lat/lon -> do nothing\n",
    "    print(path, \"no latitude/longitude — skipping\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "# --- public function: apply over the whole DataTree ---\n",
    "def add_healpix_to_dt(dt: xr.DataTree) -> xr.DataTree:\n",
    "    \"\"\"Transform nodes to HEALPix (grouped mean per cell) where possible; preserve others.\"\"\"\n",
    "    mapping = {\n",
    "        path: _add_healpix_to_dt_node(path, node.ds)\n",
    "        for path, node in dt.subtree_with_keys\n",
    "    }\n",
    "    return xr.DataTree.from_dict(mapping, name=getattr(dt, \"name\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Convert the whole tree\n",
    "healpix_dt = add_healpix_to_dt(authalic_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a specific node you know had lon/lat + x/y\n",
    "healpix_dt[\"measurements\"][\"reflectance\"][\"r10m\"]  # [\"sun_angles\"].ds\n",
    "\n",
    "\n",
    "# -> dims: angle, cell_ids\n",
    "#    coords: angle ('zenith','azimuth'), cell_ids (int64, attrs grid_name/level/indexing_scheme)\n",
    "#    data_vars: sun_angles(angle, cell_ids) [dask-backed if input was dask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo add quicklook plot here\n",
    "import xdggs\n",
    "\n",
    "# ds_plot=healpix_dt[\"conditions\"][\"geometry\"][\"sun_angles\"].isel(angle=0).compute()\n",
    "ds_plot = healpix_dt[\"measurements\"][\"reflectance\"][\"r10m\"][\"b02\"].compute()\n",
    "ds_plot.pipe(xdggs.decode).dggs.explore()\n",
    "# ds_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgnomproject(\n",
    "    cell_ids,  # array-like (N,), HEALPix pixel indices of your samples\n",
    "    data,  # array-like (N,), values per cell id\n",
    "    nside: int,\n",
    "    rot=None,  # (lon0_deg, lat0_deg, psi_deg). If None: auto-center from cell_ids (pix centers)\n",
    "    xsize: int = 800,\n",
    "    ysize: int = 800,\n",
    "    reso: float = None,  # deg/pixel on tangent plane; if None, use fov_deg\n",
    "    fov_deg=10.0,  # full FoV deg (scalar or (fx,fy))\n",
    "    nest: bool = True,  # True if your cell_ids are NESTED (and ang2pix to be done in NEST)\n",
    "    reduce: str = \"mean\",  # 'mean'|'median'|'sum'|'first' when duplicates in cell_ids\n",
    "    mask_outside: bool = True,\n",
    "    unseen_value=None,  # default to hp.UNSEEN\n",
    "    return_image_only: bool = False,\n",
    "    title: str = None,\n",
    "    cmap: str = \"viridis\",\n",
    "    vmin=None,\n",
    "    vmax=None,\n",
    "    notext: bool = False,  # True to avoid tick marks\n",
    "    hold=True,\n",
    "    sub=(1, 1, 1),\n",
    "    cbar=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Gnomonic projection from *sparse* HEALPix samples (cell_ids, data) to an image (ysize, xsize).\n",
    "\n",
    "    For each output image pixel (i,j):\n",
    "      plane (x,y) --inverse gnomonic--> (theta, phi) --HEALPix--> ipix\n",
    "      if ipix in `cell_ids`: assign aggregated value, else UNSEEN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cell_ids : (N,) int array\n",
    "        HEALPix pixel indices of your samples. Must correspond to `nside` and `nest`.\n",
    "    data : (N,) float array\n",
    "        Sample values for each cell id.\n",
    "    nside : int\n",
    "        HEALPix NSIDE used for both `cell_ids` and the image reprojection.\n",
    "    rot : (lon0_deg, lat0_deg, psi_deg) or None\n",
    "        Gnomonic center (lon, lat) and in-plane rotation psi (deg).\n",
    "        If None, we auto-center from the *centers of the provided pixels* (via hp.pix2ang).\n",
    "    xsize, ysize : int\n",
    "        Output image size (pixels).\n",
    "    reso : float or None\n",
    "        Pixel size (deg/pixel) on the tangent plane. If None, derived from `fov_deg`.\n",
    "    fov_deg : float or (float,float)\n",
    "        Full field of view in degrees.\n",
    "    nest : bool\n",
    "        Use True if your `cell_ids` correspond to NESTED indexing.\n",
    "    reduce : str\n",
    "        How to combine duplicate cell ids: 'mean'|'median'|'sum'|'first'.\n",
    "    mask_outside : bool\n",
    "        Mask pixels outside the valid gnomonic hemisphere (cosc <= 0).\n",
    "    unseen_value : float or None\n",
    "        Value for invalid pixels (default hp.UNSEEN).\n",
    "    return_image_only : bool\n",
    "        If True, return the 2D array only (no plotting).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (fig, ax, img) or img\n",
    "        If return_image_only=True, returns img (ysize, xsize).\n",
    "    \"\"\"\n",
    "    if unseen_value is None:\n",
    "        unseen_value = hp.UNSEEN\n",
    "\n",
    "    cell_ids = np.asarray(cell_ids, dtype=np.int64)\n",
    "    vals_in = np.asarray(data, dtype=float)\n",
    "    if cell_ids.shape != vals_in.shape:\n",
    "        raise ValueError(\"cell_ids and data must have the same shape (N,)\")\n",
    "\n",
    "    # -------- 1) Aggregate duplicates in cell_ids (if any) --------\n",
    "    uniq, inv = np.unique(cell_ids, return_inverse=True)  # uniq is sorted\n",
    "    if reduce == \"first\":\n",
    "        first_idx = np.full(uniq.size, -1, dtype=np.int64)\n",
    "        for i, g in enumerate(inv):\n",
    "            if first_idx[g] < 0:\n",
    "                first_idx[g] = i\n",
    "        agg_vals = vals_in[first_idx]\n",
    "    elif reduce == \"sum\":\n",
    "        agg_vals = np.zeros(uniq.size, dtype=float)\n",
    "        np.add.at(agg_vals, inv, vals_in)\n",
    "    elif reduce == \"median\":\n",
    "        agg_vals = np.empty(uniq.size, dtype=float)\n",
    "        for k, pix in enumerate(uniq):\n",
    "            agg_vals[k] = np.median(vals_in[cell_ids == pix])\n",
    "    elif reduce == \"mean\":\n",
    "        sums = np.zeros(uniq.size, dtype=float)\n",
    "        cnts = np.zeros(uniq.size, dtype=float)\n",
    "        np.add.at(sums, inv, vals_in)\n",
    "        np.add.at(cnts, inv, 1.0)\n",
    "        agg_vals = sums / np.maximum(cnts, 1.0)\n",
    "    else:\n",
    "        raise ValueError(\"reduce must be one of {'mean','median','sum','first'}\")\n",
    "\n",
    "    # -------- 2) Choose gnomonic center (rot) --------\n",
    "    if rot is None:\n",
    "        # Center from pixel centers of provided ids\n",
    "        theta_c, phi_c = hp.pix2ang(nside, uniq, nest=nest)  # colat, lon (rad)\n",
    "        # circular mean for lon, median for colat\n",
    "        lon0_deg = np.degrees(np.angle(np.mean(np.exp(1j * phi_c))))\n",
    "        lat0_deg = 90.0 - np.degrees(np.median(theta_c))\n",
    "        psi_deg = 0.0\n",
    "        rot = (lon0_deg % 360.0, float(lat0_deg), float(psi_deg))\n",
    "\n",
    "    lon0_deg, lat0_deg, psi_deg = rot\n",
    "    lon0 = np.deg2rad(lon0_deg)\n",
    "    lat0 = np.deg2rad(lat0_deg)\n",
    "    psi = np.deg2rad(psi_deg)\n",
    "\n",
    "    # -------- 3) Tangent-plane grid (gnomonic) --------\n",
    "    if reso is not None:\n",
    "        dx = np.tan(np.deg2rad(reso))\n",
    "        dy = dx\n",
    "        half_x = 0.5 * xsize * dx\n",
    "        half_y = 0.5 * ysize * dy\n",
    "    else:\n",
    "        if np.isscalar(fov_deg):\n",
    "            fx, fy = float(fov_deg), float(fov_deg)\n",
    "        else:\n",
    "            fx, fy = float(fov_deg[0]), float(fov_deg[1])\n",
    "        ax = np.deg2rad(0.5 * fx)\n",
    "        ay = np.deg2rad(0.5 * fy)\n",
    "        half_x = np.tan(ax)\n",
    "        half_y = np.tan(ay)\n",
    "\n",
    "    xs = np.linspace(-half_x, +half_x, xsize, endpoint=False) + (half_x / xsize)\n",
    "    ys = np.linspace(-half_y, +half_y, ysize, endpoint=False) + (half_y / ysize)\n",
    "    X, Y = np.meshgrid(xs, ys)  # (ysize, xsize)\n",
    "\n",
    "    # in-plane rotation psi\n",
    "    c, s = np.cos(psi), np.sin(psi)\n",
    "    Xr = c * X + s * Y\n",
    "    Yr = -s * X + c * Y\n",
    "\n",
    "    # -------- 4) Inverse gnomonic → sphere --------\n",
    "    rho = np.hypot(Xr, Yr)\n",
    "    cang = np.arctan(rho)\n",
    "    sinc, cosc = np.sin(cang), np.cos(cang)\n",
    "    sinlat0, coslat0 = np.sin(lat0), np.cos(lat0)\n",
    "\n",
    "    with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n",
    "        lat = np.arcsin(\n",
    "            cosc * sinlat0 + (Yr * sinc * coslat0) / np.where(rho == 0, 1.0, rho)\n",
    "        )\n",
    "        lon = lon0 + np.arctan2(Xr * sinc, rho * coslat0 * cosc - Yr * sinlat0 * sinc)\n",
    "\n",
    "    lon = (lon + 2 * np.pi) % (2 * np.pi)\n",
    "    theta_img = (np.pi / 2.0) - lat\n",
    "    outside = (cosc <= 0.0) if mask_outside else np.zeros_like(cosc, dtype=bool)\n",
    "\n",
    "    # -------- 5) Map image pixels to HEALPix ids --------\n",
    "    ip_img = hp.ang2pix(nside, theta_img.ravel(), lon.ravel(), nest=nest).astype(\n",
    "        np.int64\n",
    "    )\n",
    "\n",
    "    # -------- 6) Assign values by matching ip_img ∈ uniq (safe searchsorted) --------\n",
    "    # uniq is sorted; build insertion pos then check matches only where pos < len(uniq)\n",
    "    pos = np.searchsorted(uniq, ip_img, side=\"left\")\n",
    "    valid = pos < uniq.size\n",
    "    match = np.zeros_like(valid, dtype=bool)\n",
    "    match[valid] = uniq[pos[valid]] == ip_img[valid]\n",
    "\n",
    "    img_flat = np.full(ip_img.shape, unseen_value, dtype=float)\n",
    "    img_flat[match] = agg_vals[pos[match]]\n",
    "    img = img_flat.reshape(ysize, xsize)\n",
    "\n",
    "    # Mask out-of-hemisphere gnomonic region\n",
    "    if mask_outside:\n",
    "        img[outside] = unseen_value\n",
    "\n",
    "    # -------- 7) Return / plot --------\n",
    "    if return_image_only:\n",
    "        return img\n",
    "\n",
    "    # Axes in approx. \"gnomonic degrees\" (atan of plane coords)\n",
    "    x_deg = np.degrees(np.arctan(xs))\n",
    "    y_deg = np.degrees(np.arctan(ys))\n",
    "    extent = (x_deg[0], x_deg[-1], y_deg[0], y_deg[-1])\n",
    "\n",
    "    if hold:\n",
    "        fig, ax = plt.subplots(figsize=(xsize / 100, ysize / 100), dpi=100)\n",
    "    else:\n",
    "        ax = plt.subplot(sub[0], sub[1], sub[2])\n",
    "\n",
    "    im = ax.imshow(\n",
    "        np.where(img == unseen_value, np.nan, img),\n",
    "        origin=\"lower\",\n",
    "        extent=extent,\n",
    "        cmap=cmap,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        interpolation=\"nearest\",\n",
    "        aspect=\"equal\",\n",
    "    )\n",
    "    if not notext:\n",
    "        ax.set_xlabel(\"Δx (deg, gnomonic)\")\n",
    "        ax.set_ylabel(\"Δy (deg, gnomonic)\")\n",
    "    else:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    if cbar:\n",
    "        cb = fig.colorbar(im, ax=ax)\n",
    "        cb.set_label(\"value\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if hold:\n",
    "        return fig, ax  # , img\n",
    "    else:\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To JM, the default of this plot should plot all the rgion may be??\n",
    "\n",
    "import healpy as hp\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "lgnomproject(\n",
    "    ds_plot.cell_ids,\n",
    "    ds_plot,\n",
    "    2 ** ds_plot.cell_ids.attrs[\"level\"],\n",
    "    fov_deg=0.03,\n",
    "    hold=False,\n",
    "    sub=(1, 2, 1),\n",
    ")\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(ds_plot.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
